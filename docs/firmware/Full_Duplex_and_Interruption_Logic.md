# 全双工对话与实时打断逻辑 (Full-Duplex & Interruption)

实现“自然聊天”的核心在于：**AI 说话时也在听，且听到用户插话能立即反应。** 我们将复用 LiveKit Agent Framework 原生的打断机制。

---

## 1. 复用 LiveKit Agent 的打断机制

LiveKit 提供了一套成熟的“端到端”打断闭环，我们无需从零开发。

### 1.1 云端决策 (Agent-side)
- **内置 VAD 判定**：LiveKit 服务器会实时分析来自 ESP32 的音频流。
- **自动切断**：一旦判定用户开始说话，Agent 会执行：
  1. 立即停止下行 Opus 音频包的发送。
  2. 发送一个信令告诉 ESP32：“我被打断了，请清空缓冲区”。
  3. LLM 立即停止生成当前文本，准备接收用户的新问题。

### 1.2 端侧执行 (ESP32-side)
为了消除延迟感，ESP32 必须配合完成两个关键动作：
1. **持续推流 (Always On)**：无论 AI 是否在说话，ESP32 始终进行 AFE 处理并将音频推向云端。
2. **强制溢出缓冲区 (Flush Buffer)**：当收到 LiveKit 的打断事件（或本地 VAD 高优先级判定）时，立即调用：
   - `i2s_zero_dma_buffer()`：清空 I2S 硬件缓冲，让残留的声音瞬间消失。
   - `opus_decoder_reset()`：重置解码器状态，防止下一次对话出现爆音。

---

## 2. 交互方案细化：本地抢占 vs 云端仲裁

为了极致体验，我们采用“双重保障”逻辑：

| 逻辑层次 | 触发源 | 作用 | 优点 |
| :--- | :--- | :--- | :--- |
| **第一级：本地抢占** | ESP-AFE (VAD) | **纯本地决策**。当本地 AFE 检测到用户声音且能量值极高时，先行静音喇叭。 | **零延迟响应**。公仔立刻“闭嘴”，带给用户极强的操控感。 |
| **第二级：云端仲裁** | LiveKit Agent | **服务端全局决策**。根据语义和完整的音频流判定是否打断。 | **高准确度**。能区分用户是“真的在说话”还是“由于打喷嚏”误报。 |

---

## 3. 全双工数据流管理 (Task Management)

在 ESP32 上，为支撑这套逻辑，我们分配如下优先级任务：

1. **Rec Task (最高优先级)**：始终运行。麦克风 -> AFE -> VAD -> Opus -> WebSocket。
   - *注意*：必须开启 **AEC (回声消除)**，否则 AI 会被自己的声音“打断”。
2. **Play Task (中优先级)**：WebSocket -> Jitter Buffer -> Opus Decode -> I2S。
   - *控制接口*：需提供一个 `stop_playback()` 接口供逻辑层调用，立即清理所有链路缓存。
3. **Control Task (管理层)**：监听 LiveKit 数据信道 (DataChannel)。
   - 收到 `agent_speech_interrupted` 信号时，立即触发 Play Task 的停止和清理。

---

## 4. 语音输出策略：云端统一 vs 本地预存

为了保证“名人语音”的灵魂一致性，我们决定：**海绵宝宝的所有语音（包括唤醒后的第一声招呼）均由云端下发。**

- **为什么不预存本地语音包？**
    - **音质统一**：本地录音与云端 TTS 很难做到音色完美契合，混合播放会让用户“出戏”。
    - **零内存占用**：无需在有限的 Flash 空间里塞入大量的 Wave 资源，节省出更多空间给 WebRTC 缓存。
    - **内容动态**：云端可以根据当前时间说“嘿，Trump 来吃午饭了”或“太晚了，伙计”，端侧预存做不到这种灵活性。
- **代价与对策**：
    - **代价**：对唤醒后的首包延迟（TTFB）有极高要求。
    - **对策**：通过 [预连接策略](./LiveKit_Transport_and_Signaling.md#4-连接时序策略按需-on-demand-vs-预连接-pre-connected) 将延迟压低至 500ms 以内。

---

## 5. 深入解析：本地抢占的固件实现 (Firmware Implementation)

本地抢占的目标是在 **<50ms** 内让喇叭静音，这要求固件必须具备底层硬件控制权。

### 5.1 核心代码逻辑架构

在 `Rec Task` (录音线程) 的主循环中嵌入抢占逻辑：

```c
// 伪代码：高频循环(每20ms一次)
while (1) {
    // 1. 从 AFE 提取处理后的数据
    afe_fetch_result_t* res = afe_handle->fetch(afe_data);
    
    // 2. 本地抢占判定：VAD有效 && 正在播音
    if (res->vad_state == VAD_SPEECH && global_state.is_ai_talking) {
        
        // --- 动作 A：快速刹车 (硬件级) ---
        // 立即清空 I2S 输出缓冲，停止 DMA 搬运
        i2s_zero_dma_buffer(SPK_I2S_PORT); 
        
        // --- 动作 B：业务锁定 ---
        // 置位打断标志，通知播放线程丢弃缓存中的音频包
        global_state.interrupted_flag = true;
        
        // --- 动作 C：信令上报 ---
        // 通过 DataChannel 告诉云端：本地已经抢先打断了
        livekit_send_interrupt_signal();
        
        // --- 动作 D：UI 反馈 ---
        // 瞬间切换 LED 颜色到“聆听”状态
        led_set_state(STATE_LISTENING);
    }
}
```

### 5.2 避免“咔哒”声：软消音策略 (Soft Mute)
直接清空缓冲区会导致电压骤降，产生爆音。在固件中需实现：
- **快速衰减**：在执行 `i2s_zero_dma_buffer` 前，将即将输出的最后 128 个采样点（约 8ms）线性乘以 1.0 -> 0.0 的系数。
- **这种微秒级的处理能让打断听起来非常自然。**

### 5.3 状态竞争处理 (Race Condition)
要防止一种尴尬情况：AEC 还没初始化完或失效时，AI 刚一开口说话，本地 VAD 就把 AI 自己的声音当成用户在说话，从而导致“自杀式打断”。
- **固件对策**：在 AI 开始说话的前 **200ms 内**，设置一个 VAD 灵敏度屏蔽期，或者适当调高被打断的能量阈值。

---

## 6. 异常处理：回声误触发
打断逻辑最大的敌人是 **AEC 没消干净**。
- **自检**：如果 AI 刚开口说一个字就把自己吓得停了，说明 AEC 的参考信号不对。
- **方案**：优化 `Pin_Mapping_Guide.md` 中的 I2S 参考信号回路。
